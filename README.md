# emotion-tracking
![image](https://github.com/mrkien299/emotion-tracking/assets/123156510/7cccd2a9-a4b0-4ef8-ab1c-56f434c6859f)
## description
This project is an emotional tracking model that has been trained using the AFEW-VA dataset. The model is designed to predict valence and arousal values from facial expressions, allowing for the quantification of emotional states.
## reference
[1] J. Kossaifi, G. Tzimiropoulos, S. Todorovic and M. Pantic, "AFEW-VA database for valence and arousal estimation in-the-wild", in Image and Vision Computing, 2017. 

[2]  A. Dhall, R. Goecke, S. Lucey and T. Gedeon, "Collecting Large, Richly Annotated Facial-Expression Databases from Movies," in IEEE MultiMedia, vol. 19, no. 3, pp. 34-41, July-Sept. 2012.
